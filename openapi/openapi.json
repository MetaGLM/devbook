{
  "openapi": "3.0.1",
  "info": {
    "title": "Z.AI API",
    "description": "Z.AI API available endpoints",
    "license": {
      "name": "Z.AI Developer Agreement and Policy",
      "url": "https://chat.z.ai/legal-agreement/terms-of-service"
    },
    "version": "1.0.0",
    "contact": {
      "name": "Z.AI Developers",
      "url": "https://chat.z.ai/legal-agreement/privacy-policy",
      "email": "user_feedback@z.ai"
    }
  },
  "servers": [
    {
      "url": "https://api.z.ai/api",
      "description": "Production server"
    }
  ],
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "paths": {
    "/paas/v4/chat/completions": {
      "post": {
        "description": "GLM-4 offers multiple models suitable for various application scenarios.",
        "parameters": [
          {
            "$ref": "#/components/parameters/AcceptLanguage"
          }
        ],
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatCompletionRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Business processing successful",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatCompletionResponse"
                }
              }
            }
          },
          "default": {
            "description": "The request has failed.",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/paas/v4/videos/generations": {
      "post": {
        "description": "CogVideoX is a video generation large model developed by Z.AI, equipped with powerful video generation capabilities. Simply inputting text or images allows for effortless video creation.\n\nVidu: A high-performance video large model that combines high consistency and high dynamism, with precise semantic understanding and exceptional reasoning speed.",
        "parameters": [
          {
            "$ref": "#/components/parameters/AcceptLanguage"
          }
        ],
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "oneOf": [
                  {
                    "title": "CogVideoX-2",
                    "$ref": "#/components/schemas/CogVideoX2Request"
                  },
                  {
                    "title": "Vidu: Text to Video",
                    "$ref": "#/components/schemas/ViduText2VideoRequest"
                  },
                  {
                    "title": "Vidu: Image to Video",
                    "$ref": "#/components/schemas/ViduImage2VideoRequest"
                  },
                  {
                    "title": "Vidu: First & Last Frame to Video",
                    "$ref": "#/components/schemas/ViduFrames2VideoRequest"
                  },
                  {
                    "title": "Vidu: Ref to Video",
                    "$ref": "#/components/schemas/ViduReference2VideoRequest"
                  }
                ]
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Business processing successful.",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/VideoResponse"
                }
              }
            }
          },
          "default": {
            "description": "The request has failed.",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/paas/v4/async-result/{id}": {
      "get": {
        "description": "This endpoint is used to query the result of an asynchronous request.",
        "parameters": [
          {
            "$ref": "#/components/parameters/AcceptLanguage"
          },
          {
            "name": "id",
            "in": "path",
            "required": true,
            "schema": {
              "type": "string",
              "description": "Task id."
            }
          }
        ],
        "responses": {
          "200": {
            "description": "Business processing successful",
            "content": {
              "application/json": {
                "schema": {
                  "type": "object",
                  "properties": {
                    "model": {
                      "type": "string",
                      "description": "Model name."
                    },
                    "video_result": {
                      "type": "array",
                      "description": "Video generation results.",
                      "items": {
                        "type": "object",
                        "properties": {
                          "url": {
                            "type": "string",
                            "description": "Video url."
                          },
                          "cover_image_url": {
                            "type": "string",
                            "description": "Video cover url."
                          }
                        }
                      }
                    },
                    "task_status": {
                      "type": "string",
                      "description": "Processing status, `PROCESSING (processing)`, `SUCCESS (success)`, `FAIL (failure)`. Note: Processing status needs to be obtained via query."
                    },
                    "request_id": {
                      "type": "string",
                      "description": "Task number submitted by the user during the client request or generated by the platform."
                    }
                  }
                }
              }
            }
          },
          "default": {
            "description": "The request has failed.",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    },
    "/paas/v4/web_search": {
      "post": {
        "description": "The Web Search API is a specialized search engine for large language models. Building upon traditional search engine capabilities like web crawling and ranking, it enhances intent recognition to return results better suited for LLM processing (including webpage titles, URLs, summaries, site names, favicons, etc.).",
        "parameters": [
          {
            "$ref": "#/components/parameters/AcceptLanguage"
          }
        ],
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/WebSearchRequest"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "Business processing successful",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/WebSearchResponse"
                }
              }
            }
          },
          "default": {
            "description": "The request has failed.",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/Error"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "parameters": {
      "AcceptLanguage": {
        "name": "Accept-Language",
        "in": "header",
        "schema": {
          "type": "string",
          "description": "It is an HTTP request header used to inform the server of the browser's preferred list of languages, so the server can return content in the language that best matches the user's preference.",
          "default": "en-US,en",
          "enum": [
            "en-US,en"
          ]
        },
        "required": true
      }
    },
    "schemas": {
      "ChatCompletionRequest": {
        "required": [
          "model",
          "messages"
        ],
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "description": "The model code to be called.",
            "example": "glm-4-32b-0414-128k",
            "default": "glm-4-32b-0414-128k",
            "enum": [
              "glm-4-32b-0414-128k"
            ]
          },
          "messages": {
            "type": "array",
            "description": "The current conversation message list as the model’s prompt input, provided in JSON array format, e.g.,`{“role”: “user”, “content”: “Hello”}`. Possible message types include system messages, user messages, assistant messages, and tool messages.",
            "items": {
              "type": "object",
              "properties": {
                "role": {
                  "type": "string",
                  "description": "The role of the messages author. Choice between: system, user, or assistant.",
                  "example": "user",
                  "default": "user",
                  "enum": [
                    "user",
                    "assistant",
                    "system"
                  ]
                },
                "content": {
                  "type": "string",
                  "description": "Message content.",
                  "example": "What opportunities and challenges will the Chinese large model industry face in 2025?"
                }
              },
              "required": [
                "role",
                "content"
              ]
            },
            "minItems": 1,
            "maxItems": 10
          },
          "request_id": {
            "type": "string",
            "description": "Passed by the user side, needs to be unique; used to distinguish each request. If not provided by the user side, the platform will generate one by default."
          },
          "do_sample": {
            "type": "boolean",
            "example": true,
            "default": true,
            "description": "When do_sample is true, sampling strategy is enabled; when do_sample is false, sampling strategy parameters such as temperature and top_p will not take effect. Default value is `true`."
          },
          "stream": {
            "type": "boolean",
            "example": false,
            "default": false,
            "description": "This parameter should be set to false or omitted when using synchronous call. It indicates that the model returns all content at once after generating all content. Default value is false. If set to true, the model will return the generated content in chunks via standard Event Stream. When the Event Stream ends, a `data: [DONE]` message will be returned."
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature, controls the randomness of the output, must be a positive number within the range: `[0.0, 1.0]`, default value is `0.95`.",
            "format": "float",
            "example": 0.95,
            "default": 0.95,
            "minimum": 0.0,
            "maximum": 1.0
          },
          "top_p": {
            "type": "number",
            "description": "Another method of temperature sampling, value range is: `[0.0, 1.0]`, default value is `0.7`.",
            "format": "float",
            "example": 0.7,
            "default": 0.7,
            "minimum": 0.0,
            "maximum": 1.0
          },
          "max_tokens": {
            "type": "integer",
            "description": "The maximum number of tokens for model output, maximum output is `4095`, default value is `1024`.",
            "example": 1024,
            "default": 1024,
            "minimum": 1,
            "maximum": 4095
          },
          "tools": {
            "type": "array",
            "description": "A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n",
            "anyOf": [
              {
                "items": {
                  "$ref": "#/components/schemas/FunctionToolSchema"
                }
              },
              {
                "items": {
                  "$ref": "#/components/schemas/RetrievalToolSchema"
                }
              }
            ]
          }
        }
      },
      "WebSearchToolSchema": {
        "type": "object",
        "title": "Web Search",
        "properties": {
          "type": {
            "type": "string",
            "default": "web_search",
            "enum": [
              "web_search"
            ]
          },
          "web_search": {
            "$ref": "#/components/schemas/WebSearchObject"
          }
        },
        "required": [
          "type",
          "web_search"
        ],
        "additionalProperties": false
      },
      "WebSearchObject": {
        "type": "object",
        "properties": {
          "enable": {
            "type": "boolean",
            "description": "Whether to enable search functionality.\nDefault is `false`. Set to true to `enable`."
          },
          "search_engine": {
            "type": "string",
            "description": "Type of search engine.\nDefault is `search_std`. Supports: `search_std`, `search_pro`, `search_pro_sogou`, `search_pro_quark`, `search_pro_jina`, `search_pro_bing`.",
            "enum": [
              "search_std",
              "search_pro",
              "search_pro_sogou",
              "search_pro_quark",
              "search_pro_jina",
              "search_pro_bing"
            ]
          },
          "search_query": {
            "type": "string",
            "description": "Force trigger a search"
          },
          "count": {
            "type": "integer",
            "description": "Number of returned results\nRange: `1-50`, max `50` results per search\nDefault is `10`\nSupported engines: `search_std`, `search_pro`, `search_pro_sogou`\nFor `search_pro_sogou`: allowed values are `10`, `20`, `30`, `40`, `50`",
            "minimum": 1,
            "maximum": 50
          },
          "search_domain_filter": {
            "type": "string",
            "description": "Limits search results to specified whitelisted domains. Whitelist: input domains directly (e.g., www.example.com)\nSupported engines: `search_std`, `search_pro`, `search_pro_sogou`, `search_pro_Jina`"
          },
          "search_recency_filter": {
            "type": "string",
            "description": "Limits search to a specific time range.\nDefault is `noLimit`\nValues:\n`oneDay`, within a day\n`oneWeek`, within a week\n`oneMonth`, within a month\n`oneYear`, within a year\n`noLimit`, no limit (default)\nSupported engines: `search_std`, `search_pro`, `search_pro_sogou`, `search_pro_quark`",
            "enum": [
              "oneDay",
              "oneWeek",
              "oneMonth",
              "oneYear",
              "noLimit"
            ]
          },
          "content_size": {
            "type": "string",
            "description": "Number of characters for webpage summaries.\nDefault is `medium`\n`medium`: Balanced mode for most queries. 400-600 characters\n`high`: Maximizes context for comprehensive answers, 2500 characters.",
            "enum": [
              "medium",
              "high"
            ]
          },
          "result_sequence": {
            "type": "string",
            "description": "Specifies whether search results are shown before or after model response. Options: `before`, `after`. Default is `after`",
            "enum": [
              "before",
              "after"
            ]
          },
          "search_result": {
            "type": "boolean",
            "description": "Whether to return search results in the response.\nDefault is `false`"
          },
          "require_search": {
            "type": "boolean",
            "description": "Whether to force model response based on search result.\nDefault is `false`"
          },
          "search_prompt": {
            "type": "string",
            "description": "Prompt to customize how search results are processed.\nDefault Prompt:\n`You are an intelligent Q&A expert with the ability to synthesize information, recognize time, understand semantics, and clean contradictory data. The current date is {{current_date}}. Use this as the only time reference. Based on the following information, provide a comprehensive and accurate answer to the user's question.Only extract valuable content for the answer. Ensure the answer is timely and authoritative. State the answer directly without citing data sources or internal processes.`"
          }
        },
        "required": [
          "search_engine"
        ]
      },
      "FunctionToolSchema": {
        "type": "object",
        "title": "Function Call",
        "properties": {
          "type": {
            "type": "string",
            "default": "function",
            "enum": [
              "function"
            ]
          },
          "function": {
            "$ref": "#/components/schemas/FunctionObject"
          }
        },
        "required": [
          "type",
          "function"
        ],
        "additionalProperties": false
      },
      "FunctionObject": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.",
            "minLength": 1,
            "maxLength": 64,
            "pattern": "^[a-zA-Z0-9_-]+$"
          },
          "description": {
            "type": "string",
            "description": "A description of what the function does, used by the model to choose when and how to call the function."
          },
          "parameters": {
            "$ref": "#/components/schemas/FunctionParameters"
          }
        },
        "required": [
          "name",
          "description",
          "parameters"
        ]
      },
      "FunctionParameters": {
        "type": "object",
        "description": "Parameters defined using JSON Schema. Must pass a JSON Schema object to accurately define accepted parameters. Omit if no parameters are needed when calling the function.",
        "additionalProperties": true
      },
      "RetrievalToolSchema": {
        "type": "object",
        "title": "Retrieval",
        "properties": {
          "type": {
            "type": "string",
            "default": "retrieval",
            "enum": [
              "retrieval"
            ]
          },
          "retrieval": {
            "$ref": "#/components/schemas/RetrievalObject"
          }
        },
        "required": [
          "type",
          "retrieval"
        ],
        "additionalProperties": false
      },
      "RetrievalObject": {
        "type": "object",
        "properties": {
          "knowledge_id": {
            "type": "string",
            "description": "Knowledge base ID, created or obtained from the platform"
          },
          "prompt_template": {
            "type": "string",
            "description": "Prompt template for requesting the model, a custom request template containing placeholders `{{ knowledge }}` and `{{ question }}`. Default template: `Search for the answer to the question `{{question}}` in the document `{{ knowledge }}`. If an answer is found, respond only using statements from the document; if no answer is found, use your own knowledge to answer and inform the user that the information is not from the document. Do not repeat the question, start the answer directly.`"
          }
        },
        "required": [
          "knowledge_id"
        ]
      },
      "ChatCompletionResponse": {
        "type": "object",
        "properties": {
          "id": {
            "description": "Task ID",
            "type": "string"
          },
          "request_id": {
            "description": "Request ID",
            "type": "string"
          },
          "created": {
            "description": "Request creation time, Unix timestamp in seconds",
            "type": "integer"
          },
          "model": {
            "description": "Model name",
            "type": "string"
          },
          "choices": {
            "type": "array",
            "description": "List of model responses",
            "items": {
              "type": "object",
              "properties": {
                "index": {
                  "type": "integer",
                  "description": "Result index"
                },
                "message": {
                  "$ref": "#/components/schemas/ChatCompletionResponseMessage"
                },
                "finish_reason": {
                  "type": "string",
                  "description": "Reason for model inference termination. Can be ‘stop’, ‘tool_calls’, ‘length’, ‘sensitive’, or ‘network_error’."
                }
              }
            }
          },
          "usage": {
            "type": "object",
            "description": "Token usage statistics returned when the model call ends.",
            "properties": {
              "prompt_tokens": {
                "type": "integer",
                "description": "Number of tokens in user input"
              },
              "completion_tokens": {
                "type": "integer",
                "description": "Number of tokens in model output"
              },
              "total_tokens": {
                "type": "integer",
                "description": "Total number of tokens"
              }
            }
          }
        }
      },
      "ChatCompletionResponseMessage": {
        "type": "object",
        "properties": {
          "role": {
            "type": "string",
            "description": "Current conversation role, default is ‘assistant’ (model)",
            "example": "assistant"
          },
          "content": {
            "type": "string",
            "description": "Current conversation content. Hits function is null, otherwise returns model inference result."
          },
          "tool_calls": {
            "type": "array",
            "description": "Function names and parameters generated by the model that should be called.",
            "items": {
              "$ref": "#/components/schemas/ChatCompletionResponseMessageToolCall"
            }
          }
        }
      },
      "ChatCompletionResponseMessageToolCall": {
        "type": "object",
        "properties": {
          "function": {
            "type": "object",
            "description": "Contains the function name and JSON format parameters generated by the model.",
            "properties": {
              "name": {
                "type": "string",
                "description": "Model-generated function name."
              },
              "arguments": {
                "type": "object",
                "description": "JSON format of the function call parameters generated by the model. Validate the parameters before calling the function."
              }
            },
            "required": [
              "name",
              "arguments"
            ]
          },
          "id": {
            "type": "string",
            "description": "Unique identifier for the hit function."
          },
          "type": {
            "type": "string",
            "description": "Tool type called by the model, currently only supports ‘function’."
          }
        }
      },
      "CogVideoX2Request": {
        "allOf": [
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "description": "The model code to be called.",
                "enum": [
                  "cogvideox-2"
                ]
              },
              "prompt": {
                "type": "string",
                "description": "Text description of the video, maximum input length of 512 Tokens. Either image_url or prompt must be provided, or both."
              },
              "quality": {
                "type": "string",
                "description": "Output mode, default is `speed`.\n `quality`: Prioritizes quality, higher generation quality. \n`speed`: Prioritizes speed, faster generation time, relatively lower quality.",
                "example": "speed",
                "enum": [
                  "speed",
                  "quality"
                ]
              },
              "with_audio": {
                "type": "boolean",
                "description": "Whether to generate AI sound effects. Default: `false` (no sound effects).",
                "example": false
              },
              "image_url": {
                "description": "Image to base the content generation on. If provided, the system will operate based on this image. Supports URL or Base64 encoded images. Image requirements: Supports .png, .jpeg, .jpg formats; image size: no more than 5M. Either image_url or prompt must be provided, or both.",
                "oneOf": [
                  {
                    "title": "Image URL",
                    "type": "string",
                    "format": "uri",
                    "example": "https://example.com/image.png"
                  },
                  {
                    "title": "Base64 Encoded Image",
                    "type": "string",
                    "format": "byte",
                    "example": "data:image/png;base64, XXX"
                  }
                ]
              },
              "size": {
                "type": "string",
                "description": "Default: If not specified, the short side of the generated video defaults to 1080, with the long side scaled according to the original image ratio. Supports up to 4K resolution. Resolution options: `720x480`, `1024x1024`, `1280x960`, `960x1280`, `1920x1080`, `1080x1920`, `2048x1080`, `3840x2160`.",
                "example": "1920x1080",
                "enum": [
                  "720x480",
                  "1024x1024",
                  "1280x960",
                  "960x1280",
                  "1920x1080",
                  "1080x1920",
                  "2048x1080",
                  "3840x2160"
                ]
              },
              "fps": {
                "type": "integer",
                "description": "Video frame rate (FPS), optional values are `30` or `60`. Default: `30`.",
                "example": 30,
                "enum": [
                  30,
                  60
                ]
              }
            },
            "required": [
              "model"
            ]
          },
          {
            "$ref": "#/components/schemas/VideoCommonRequest"
          }
        ]
      },
      "ViduText2VideoRequest": {
        "allOf": [
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "description": "The model code to be called.",
                "enum": [
                  "viduq1-text"
                ]
              },
              "prompt": {
                "type": "string",
                "description": "Text description of the video, maximum input length of 512 Tokens."
              },
              "style": {
                "type": "string",
                "description": "Style\nDefault: `general`\nOptional values: `general` , `anime`\n`general`: General style, can be controlled using prompts to define the style.\n`anime`: Anime style, optimized for anime-specific visuals. The style can be controlled using different anime-themed prompts.",
                "enum": [
                  "general",
                  "anime"
                ]
              },
              "duration": {
                "type": "integer",
                "description": "Video duration parameter.\nDefault: `5` , Optional: `5`.",
                "example": 5,
                "enum": [
                  5
                ]
              },
              "aspect_ratio": {
                "type": "string",
                "description": "Aspect ratio\nDefault: `16:9`, Optional values: `16:9`, `9:16`, `1:1`",
                "example": "16:9",
                "enum": [
                  "16:9",
                  "9:16",
                  "1:1"
                ]
              },
              "size": {
                "type": "string",
                "description": "Resolution parameter\nDefault: `1920x1080`, Optional: `1920x1080`",
                "example": "1920x1080",
                "enum": [
                  "1920x1080"
                ]
              },
              "movement_amplitude": {
                "type": "string",
                "description": "Motion amplitude\nDefault: `auto` , Optional values:  `auto` ,`small` ,`medium` ,`large`",
                "example": "auto",
                "enum": [
                  "auto",
                  "small",
                  "medium",
                  "large"
                ]
              }
            },
            "required": [
              "model",
              "prompt"
            ]
          },
          {
            "$ref": "#/components/schemas/VideoCommonRequest"
          }
        ]
      },
      "ViduImage2VideoRequest": {
        "allOf": [
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "description": "The model code to be called.",
                "enum": [
                  "viduq1-image",
                  "vidu2-image"
                ]
              },
              "prompt": {
                "type": "string",
                "description": "Text description of the video, maximum input length of 512 Tokens. Either image_url or prompt must be provided, or both."
              },
              "image_url": {
                "type": "string",
                "description": "The model will use the image provided in this parameter as the first frame to generate the video.\nOnly `1` image is supported.\nSupported formats: `png` , `jpeg` , `jpg` , `webp` .\nImage aspect ratio must be less than `1:4` or `4:1`.\nImage file size must not exceed `50MB`.\nNote: After Base64 decoding, the byte length must be less than 50 MB, and the encoding must include the appropriate content type string (e.g., `data:image/png;base64,{base64_encode}`).",
                "oneOf": [
                  {
                    "title": "Image URL",
                    "type": "string",
                    "format": "uri",
                    "example": "https://example.com/image.png"
                  },
                  {
                    "title": "Base64 Encoded Image",
                    "type": "string",
                    "format": "byte",
                    "example": "data:image/png;base64, XXX"
                  }
                ]
              },
              "duration": {
                "oneOf": [
                  {
                    "title": "viduq1-image",
                    "type": "integer",
                    "description": "Video duration parameter.\nDefault: `5` , Optional: `5`.",
                    "example": 5,
                    "enum": [
                      5
                    ]
                  },
                  {
                    "title": "viduq2-image",
                    "type": "integer",
                    "description": "Video duration parameter.\nDefault: `4` , Optional: `4`.",
                    "example": 4,
                    "enum": [
                      4
                    ]
                  }
                ]
              },
              "size": {
                "oneOf": [
                  {
                    "title": "viduq1-image",
                    "type": "string",
                    "description": "Resolution parameter\nDefault: `1920x1080`, Optional: `1920x1080`",
                    "example": "1920x1080",
                    "enum": [
                      "1920x1080"
                    ]
                  },
                  {
                    "title": "viduq2-image",
                    "type": "string",
                    "description": "Resolution parameter\nDefault: `1280x720`, Optional: `1280x720`",
                    "example": "1280x720",
                    "default": "1280x720",
                    "enum": [
                      "1280x720"
                    ]
                  }
                ]
              },
              "movement_amplitude": {
                "type": "string",
                "description": "Motion amplitude\nDefault: `auto` , Optional values:  `auto` ,`small` ,`medium` ,`large`",
                "example": "auto",
                "enum": [
                  "auto",
                  "small",
                  "medium",
                  "large"
                ]
              },
              "with_audio": {
                "type": "boolean",
                "description": "Add background music to the generated video."
              }
            },
            "required": [
              "model"
            ]
          },
          {
            "$ref": "#/components/schemas/VideoCommonRequest"
          }
        ]
      },
      "ViduFrames2VideoRequest": {
        "allOf": [
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "description": "The model code to be called.",
                "enum": [
                  "viduq1-start-end",
                  "vidu2-start-end"
                ]
              },
              "prompt": {
                "type": "string",
                "description": "Text description of the video, maximum input length of 512 Tokens. Either image_url or prompt must be provided, or both."
              },
              "image_url": {
                "type": "array",
                "description": "Images\nSupports input of two images: the first uploaded image will be treated as the first frame, and the second image as the last frame. The model will use the images provided in this parameter to generate a video.\nThe resolutions of the two input images (first and last frame) must be similar, with the ratio between the resolution of the first frame and the resolution of the last frame falling within `0.8–1.25`. Additionally, the image aspect ratio must be less than `1:4` or `4:1`.\nSupports image URLs or images encoded in Base64 (ensure accessibility; using image URLs is recommended).\nSupported formats: `png`, `jpeg`, `.jpg`, `webp`.\nImage file size must not exceed `50 MB`.\nNote: After Base64 decoding, the byte length must be less than 50 MB, and the encoding must include the appropriate content type string, such as `data:image/png;base64,{base64_encode}`.",
                "items": {
                  "type": "string",
                  "minLength": 1
                },
                "minItems": 1,
                "maxItems": 2
              },
              "duration": {
                "oneOf": [
                  {
                    "title": "viduq1-start-end",
                    "type": "integer",
                    "description": "Video duration parameter.\nDefault: `5` , Optional: `5`.",
                    "example": 5,
                    "enum": [
                      5
                    ]
                  },
                  {
                    "title": "vidu2-start-end",
                    "type": "integer",
                    "description": "Video duration parameter.\nDefault: `4` , Optional: `4`.",
                    "example": 4,
                    "enum": [
                      4
                    ]
                  }
                ]
              },
              "size": {
                "oneOf": [
                  {
                    "title": "viduq1-start-end",
                    "type": "string",
                    "description": "Resolution parameter\nDefault: `1920x1080`, Optional: `1920x1080`",
                    "example": "1920x1080",
                    "enum": [
                      "1920x1080"
                    ]
                  },
                  {
                    "title": "vidu2-start-end",
                    "type": "string",
                    "description": "Resolution parameter\nDefault: `1280x720`, Optional: `1280x720`",
                    "example": "1280x720",
                    "default": "1280x720",
                    "enum": [
                      "1280x720"
                    ]
                  }
                ]
              },
              "movement_amplitude": {
                "type": "string",
                "description": "Motion amplitude\nDefault: `auto` , Optional values:  `auto` ,`small` ,`medium` ,`large`",
                "example": "auto",
                "enum": [
                  "auto",
                  "small",
                  "medium",
                  "large"
                ]
              },
              "with_audio": {
                "type": "boolean",
                "description": "Add background music to the generated video."
              }
            },
            "required": [
              "model"
            ]
          },
          {
            "$ref": "#/components/schemas/VideoCommonRequest"
          }
        ]
      },
      "ViduReference2VideoRequest": {
        "allOf": [
          {
            "type": "object",
            "properties": {
              "model": {
                "type": "string",
                "description": "The model code to be called.",
                "enum": [
                  "vidu2-reference"
                ]
              },
              "prompt": {
                "type": "string",
                "description": "Text description of the video, maximum input length of 512 Tokens. Either image_url or prompt must be provided, or both."
              },
              "image_url": {
                "type": "array",
                "description": "Image reference\nSupports input of 1 to 3 images. The model will use the themes from the images provided in this parameter as references to generate a video with consistent subjects.\n1. Supports image URLs or images encoded in Base64 (ensure accessibility; it is recommended to prioritize using image URLs).\n2. Supported formats: `png`, `jpeg`, `.jpg`, `webp`.\n3. Image resolution must not be smaller than `128x128`, and the aspect ratio must be less than `1:4` or `4:1`.\n4. Image file size must not exceed `50 MB`.\n5. Note: After Base64 decoding, the byte length must be less than 50 MB, and the encoding must include the proper content-type string, such as `data:image/png;base64,{base64_encode}`.",
                "items": {
                  "type": "string",
                  "minLength": 1
                },
                "minItems": 1,
                "maxItems": 3
              },
              "duration": {
                "title": "vidu2-reference",
                "type": "integer",
                "description": "Video duration parameter.\nDefault: `4` , Optional: `4`.",
                "example": 4,
                "enum": [
                  4
                ]
              },
              "aspect_ratio": {
                "type": "string",
                "description": "Aspect ratio\nDefault: `16:9`, Optional values: `16:9`, `9:16`, `1:1`",
                "example": "16:9",
                "enum": [
                  "16:9",
                  "9:16",
                  "1:1"
                ]
              },
              "size": {
                "title": "vidu2-reference ",
                "type": "string",
                "description": "Resolution parameter\nDefault: `1280x720`, Optional: `1280x720`",
                "example": "1280x720",
                "enum": [
                  "1280x720"
                ]
              },
              "movement_amplitude": {
                "type": "string",
                "description": "Motion amplitude\nDefault: `auto` , Optional values:  `auto` ,`small` ,`medium` ,`large`",
                "example": "auto",
                "enum": [
                  "auto",
                  "small",
                  "medium",
                  "large"
                ]
              },
              "with_audio": {
                "type": "boolean",
                "description": "Add background music to the generated video."
              }
            },
            "required": [
              "model"
            ]
          },
          {
            "$ref": "#/components/schemas/VideoCommonRequest"
          }
        ]
      },
      "VideoCommonRequest": {
        "type": "object",
        "properties": {
          "request_id": {
            "type": "string",
            "description": "Provided by the client, must be unique; used to distinguish each request’s unique identifier. If not provided by the client, the platform will generate one by default."
          },
          "user_id": {
            "type": "string",
            "description": "Unique ID of the end-user, assists the platform in intervening in end-user violations, generating illegal or inappropriate information, or other abusive behaviors. ID length requirement: minimum `6` characters, maximum `128` characters."
          }
        }
      },
      "VideoResponse": {
        "type": "object",
        "properties": {
          "model": {
            "description": "Model name used in this call.",
            "type": "string"
          },
          "id": {
            "description": "Task order number generated by the Z.AI, use this order number when calling the request result interface.",
            "type": "string"
          },
          "request_id": {
            "description": "Task number submitted by the user during the client request or generated by the platform.",
            "type": "string"
          },
          "task_status": {
            "description": "Processing status, `PROCESSING (processing)`,` SUCCESS (success)`, `FAIL (failure)`. Results need to be obtained via query.",
            "type": "string"
          }
        }
      },
      "WebSearchRequest": {
        "type": "object",
        "properties": {
          "search_query": {
            "type": "string",
            "description": "The content to be searched."
          },
          "search_engine": {
            "type": "string",
            "description": "The search engine code to call. Currently supported:\n`search_std`: Z.AI Basic Search Engine\n`search_pro`: Z.AI Advanced Search Engine\n`search_pro_sogou`: Sogou Search Engine\n`search_pro_quark`: Quark Search Engine.\n`search_pro_jina`: jina.ai Search Engine\nDefault is `search_std`.",
            "example": "search_std",
            "default": "search_std",
            "enum": [
              "search_std",
              "search_pro",
              "search_pro_sogou",
              "search_pro_quark",
              "search_pro_jina"
            ]
          },
          "count": {
            "type": "integer",
            "description": "The number of results to return\nFillable range: `1-50`, maximum `50` results per single search\nDefault is `10`\nSupported search engines: \n`search_pro`、`search_std`、`search_pro_sogou`\nSogou: Optional enumerated values are `10`, `20`, `30`, `40`, `50`.",
            "minimum": 1,
            "maximum": 50
          },
          "search_domain_filter": {
            "type": "string",
            "description": "Used to limit the scope of search results and only return content from specified whitelist domains.\nWhitelist: Directly enter the domain name (e.g., `www.example.com`)\nSupported search engines: \n`search_std`、`search_pro`、`search_pro_sogou`、`search_pro_jina`"
          },
          "search_recency_filter": {
            "type": "string",
            "description": "Search for webpages within a specified time range.\nDefault is `noLimit`\nFillable values:\n`oneDay`: within one day\n`oneWeek`: within one week\n`oneMonth`: within one month\n`oneYear`: within one year\n`noLimit`: no limit (default)\nSupported search engines: \n`search_std`、`search_pro`、`search_pro_sogou`、`search_pro_quark`",
            "enum": [
              "oneDay",
              "oneWeek",
              "oneMonth",
              "oneYear",
              "noLimit"
            ]
          },
          "content_size": {
            "type": "string",
            "description": "The number of characters in the webpage summary.\nDefault is `medium`\n`medium`: Balanced mode for most queries, 400-600 characters\n`high`: Maximizes context for comprehensive answers, 2500 characters.",
            "example": "medium",
            "default": "medium",
            "enum": [
              "medium",
              "high"
            ]
          },
          "request_id": {
            "type": "string",
            "description": "User-provided unique identifier for distinguishing requests. If not provided, the platform will generate one."
          },
          "user_id": {
            "type": "string",
            "description": "Unique ID of the end user, helping the platform intervene in illegal activities, inappropriate content generation, or other abuses. ID length: 6 to 128 characters."
          }
        },
        "required": [
          "search_query"
        ]
      },
      "WebSearchResponse": {
        "type": "object",
        "properties": {
          "id": {
            "description": "Task ID.",
            "type": "string"
          },
          "created": {
            "description": "Request creation time, Unix timestamp in seconds.",
            "type": "integer"
          },
          "search_intent": {
            "description": "Search intent results.",
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "query": {
                  "type": "string",
                  "description": "Original search query."
                },
                "intent": {
                  "type": "string",
                  "description": "Recognized intent type.\n`SEARCH_ALL`: Search the entire web\n`SEARCH_NONE`: No search intent"
                },
                "keywords": {
                  "type": "string",
                  "description": "Rewritten search keywords."
                }
              }
            }
          },
          "search_result": {
            "description": "Search results.",
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "title": {
                  "type": "string",
                  "description": "Title."
                },
                "content": {
                  "type": "string",
                  "description": "Content summary."
                },
                "link": {
                  "type": "string",
                  "description": "Result URL."
                },
                "media": {
                  "type": "string",
                  "description": "Website name."
                },
                "icon": {
                  "type": "string",
                  "description": "Website icon."
                },
                "refer": {
                  "type": "string",
                  "description": "Index number."
                },
                "publish_date": {
                  "type": "string",
                  "description": "Website publication date."
                }
              }
            }
          }
        }
      },
      "BadRequestData": {},
      "UnauthorizedData": {},
      "NotFoundData": {},
      "Error": {
        "required": [
          "code",
          "message"
        ],
        "type": "object",
        "properties": {
          "code": {
            "type": "integer",
            "format": "int32"
          },
          "message": {
            "type": "string"
          }
        }
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "description": "Use the following format for authentication: Bearer [<your api key>](https://z.ai/manage-apikey/apikey-list)"
      }
    }
  }
}